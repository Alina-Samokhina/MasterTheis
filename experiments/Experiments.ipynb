{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T16:28:22.188727Z",
     "start_time": "2021-05-30T16:28:21.336130Z"
    }
   },
   "outputs": [],
   "source": [
    "import patch_path\n",
    "\n",
    "\"\"\n",
    "import torchcde\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T16:28:24.358124Z",
     "start_time": "2021-05-30T16:28:22.190071Z"
    }
   },
   "outputs": [],
   "source": [
    "from mt_code.datasets import get_data, PersonData, P300Dataset\n",
    "from mt_code.models import NeuralCde, OdeLstm, LmuLstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T16:28:24.375549Z",
     "start_time": "2021-05-30T16:28:24.359479Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alina/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LmuLstm(\n",
       "  (rnn_cell): LMUCell(\n",
       "    (input_encoder): Linear(in_features=2, out_features=8, bias=True)\n",
       "    (hidden_encoder): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (memory_encoder): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (input_linear): Linear(in_features=2, out_features=8, bias=True)\n",
       "    (hidden_linear): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (memory_linear): Linear(in_features=8, out_features=8, bias=True)\n",
       "    (tanh): Tanh()\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (fc): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LmuLstm(in_features = 2, hidden_size = 8, order = 8, out_feature = 1, theta = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T16:28:24.381298Z",
     "start_time": "2021-05-30T16:28:24.376918Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import argparse\n",
    "import torch.utils.data as data\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics.functional import accuracy, f1\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from mt_code.runners import Learner as IrregularSequenceLearner\n",
    "from mt_code.datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:25:31.513050Z",
     "start_time": "2021-05-30T03:25:31.503213Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### old"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:19:54.276765Z",
     "start_time": "2021-05-30T03:19:54.254069Z"
    },
    "hidden": true
   },
   "source": [
    "class IrregularSequenceLearner(pl.LightningModule):\n",
    "    def __init__(self, model, lr=0.005, timestamps = True, num_classes = 7, class_weights = None):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.timestamps = timestamps\n",
    "        self.num_classes = num_classes\n",
    "        self.class_weights = class_weights\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        if self.timestamps:\n",
    "            if len(batch) == 4:\n",
    "                x, t, y, mask = batch\n",
    "            else:\n",
    "                x, t, y = batch\n",
    "                mask = None\n",
    "            y_hat = self.model.forward(x, t, mask)\n",
    "            \n",
    "        else:\n",
    "            x, y = batch\n",
    "            y_hat = self.model.forward(x)\n",
    "            \n",
    "        y_hat = y_hat.view(-1, y_hat.size(-1))\n",
    "        y = y.view(-1)\n",
    "        f1_score = f1(nn.functional.softmax(y_hat), y)\n",
    "        loss = nn.CrossEntropyLoss()(y_hat, y)\n",
    "        preds = torch.argmax(y_hat.detach(), dim=-1)\n",
    "        acc = accuracy(preds, y)\n",
    "        \n",
    "        self.log(\"train_acc\", acc, prog_bar=True)\n",
    "        self.log(\"train_f1\", f1_score, prog_bar=True)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        return {\"loss\": loss, \"acc\": acc, \"f1\": f1}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        if self.timestamps:\n",
    "            if len(batch) == 4:\n",
    "                x, t, y, mask = batch\n",
    "            else:\n",
    "                x, t, y = batch\n",
    "                mask = None\n",
    "            y_hat = self.model.forward(x, t, mask)\n",
    "        else:\n",
    "            x, y = batch\n",
    "            y_hat = self.model.forward(x)\n",
    "            \n",
    "        y_hat = y_hat.view(-1, y_hat.size(-1))\n",
    "        y = y.view(-1)\n",
    "\n",
    "        loss = nn.CrossEntropyLoss(weight = self.class_weights)(y_hat, y)\n",
    "\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        acc = accuracy(preds, y)\n",
    "        f1_score = f1(preds, y)\n",
    "\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_f1\", f1_score, prog_bar=True)\n",
    "        self.log(\"val_acc\", acc, prog_bar=True)\n",
    "        return {\"loss\": loss, \"acc\": acc, \"f1\": f1}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Here we just reuse the validation_step for testing\n",
    "        return self.validation_step(batch, batch_idx)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T09:30:38.565660Z",
     "start_time": "2021-05-30T09:30:38.544941Z"
    },
    "hidden": true
   },
   "source": [
    "\n",
    "def load_dataset(ds = 'activity', timestamps = True, coeffs = False, batch_size = 128, data_dir = '../data/person'):\n",
    "    if ds == 'activity':\n",
    "        dataset = PersonData(data_dir = data_dir)\n",
    "        train_ts = torch.Tensor(dataset.train_t)\n",
    "        test_ts = torch.Tensor(dataset.test_t)\n",
    "    elif ds == 'p300':\n",
    "        dataset = P300Dataset(data_dir = data_dir)\n",
    "        dataset.get_data_for_experiments(True)\n",
    "        train_ts = torch.Tensor(dataset.train_t)[:, :, None]\n",
    "        test_ts = torch.Tensor(dataset.test_t)[:, :, None]\n",
    "    else:\n",
    "        raise ValueError(f'No such dataset: {ds}, try \"activity\"')\n",
    "        \n",
    "    \n",
    "    train_x = torch.Tensor(dataset.train_x)\n",
    "    test_x = torch.Tensor(dataset.test_x) \n",
    "    \n",
    "    train_y = torch.LongTensor(dataset.train_y)\n",
    "    test_y = torch.LongTensor(dataset.test_y)\n",
    "    \n",
    "    \n",
    "    print(train_ts.size(), train_x.size())\n",
    "    \n",
    "    if coeffs:\n",
    "        train_x = torch.cat([train_ts, train_x], dim = 2)\n",
    "        train_x = torchcde.natural_cubic_coeffs(torch.Tensor(dataset.train_x))#, dtype=torch.float32))\n",
    "        test_x = torch.cat([test_ts, test_x], dim = 2)\n",
    "        test_x = torchcde.natural_cubic_coeffs(torch.Tensor(dataset.test_x))#, dtype=torch.float32))\n",
    "\n",
    "    \n",
    "    if timestamps:\n",
    "        train = data.TensorDataset(train_x, train_ts, train_y)\n",
    "        test = data.TensorDataset(test_x, test_ts, test_y)\n",
    "    else:\n",
    "        train = data.TensorDataset(train_x,  train_y)\n",
    "        test = data.TensorDataset(test_x,  test_y)        \n",
    "    return_sequences = True\n",
    " \n",
    "    \n",
    "    counts = test_y.unique(return_counts=True)[1].to(torch.float)\n",
    "    class_balance = counts / counts.min()\n",
    "    \n",
    "    trainloader = data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    testloader = data.DataLoader(test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    in_features = train_x.size(-1)\n",
    "    num_classes = int(torch.max(train_y).item() + 1)\n",
    "    return trainloader, testloader, in_features, num_classes, return_sequences, class_balance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T09:30:41.763430Z",
     "start_time": "2021-05-30T09:30:39.311859Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-d53e2e2a20ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trainloader, testloader, in_features, num_classes, return_sequences, class_balance = load_dataset(\n\u001b[0;32m----> 2\u001b[0;31m     'p300', timestamps = False, coeffs = False, batch_size = 128, data_dir = '../data/demons/nery_demons_dataset')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-78-a911b2ba9516>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(ds, timestamps, coeffs, batch_size, data_dir)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'p300'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP300Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data_for_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mtrain_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_t\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtest_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_t\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/MasterThesis/mt_code/datasets/p300.py\u001b[0m in \u001b[0;36mget_data_for_experiments\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_data_for_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mall_x\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mall_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mall_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mall_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/MasterThesis/mt_code/datasets/p300.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_to_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                         \u001b[0;31m# eliminating sessions order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/MasterThesis/mt_code/datasets/p300.py\u001b[0m in \u001b[0;36mtransform_to_epochs\u001b[0;34m(self, sessions)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform_to_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0meegs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msessions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eeg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mstarts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'starts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         epochs = np.concatenate(\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 return last_step.fit(Xt, y,\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/MasterThesis/mt_code/datasets/transforms.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignals\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# double T for scaling each channel separately\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mscaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    792\u001b[0m                                 \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m                                 force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'requires_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m                 raise ValueError(\n\u001b[1;32m    417\u001b[0m                     \u001b[0;34mf\"This {self.__class__.__name__} estimator \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_get_tags\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mcollected_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbase_class\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_more_tags'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m                 \u001b[0;31m# need the if because mixins might not have _more_tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0;31m# but might do redundant work in estimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainloader, testloader, in_features, num_classes, return_sequences, class_balance = load_dataset(\n",
    "    'p300', timestamps = False, coeffs = False, batch_size = 128, data_dir = '../data/demons/nery_demons_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:21:01.953720Z",
     "start_time": "2021-05-30T03:20:59.607344Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alina/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7769, 32, 1]) torch.Size([7769, 32, 7])\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader, in_features, num_classes, return_sequences, class_balance = load_dataset(\n",
    "    'activity', timestamps = False, coeffs = False, batch_size = 128, data_dir = '../data/person')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## P300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### CDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T09:21:50.083793Z",
     "start_time": "2021-05-30T09:21:50.075882Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alina/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: Checkpoint directory logs/models/demons/cde/ exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_f1',\n",
    "    mode = 'max',\n",
    "    dirpath='logs/models/demons/cde/',\n",
    "    save_top_k = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T09:21:21.859337Z",
     "start_time": "2021-05-30T09:20:59.797114Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alina/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape:  torch.Size([45232, 35, 8])\n",
      "train_y.shape:  torch.Size([45232])\n",
      "Total number of train sequences: 45232\n",
      "Total number of test  sequences: 11308\n",
      "torch.Size([45232, 35, 1]) torch.Size([45232, 35, 8])\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader, in_features, num_classes, return_sequences, class_balance = load_dataset(\n",
    "    'p300', timestamps=False, coeffs=True, batch_size=1024,  data_dir = '../data/demons/nery_demons_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T09:21:41.987520Z",
     "start_time": "2021-05-30T09:21:41.967406Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alina/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "accuracy =  torchmetrics.Accuracy()\n",
    "f1 =  torchmetrics.F1(num_classes, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T09:21:42.127000Z",
     "start_time": "2021-05-30T09:21:42.118120Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cde = NeuralCde(\n",
    "    8,#original num of features\n",
    "    8,\n",
    "    num_classes,\n",
    "\n",
    "    return_sequences=False,\n",
    "    #memory = True,\n",
    "    #gated=True\n",
    "    #solver_type='fixed_rk4',\n",
    ")\n",
    "learn = IrregularSequenceLearner(cde, lr=0.05, timestamps=True, class_weights = 1/class_balance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T09:20:53.912433Z",
     "start_time": "2021-05-30T09:20:45.505Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    gradient_clip_val=1,\n",
    "    callbacks=[checkpoint_callback]\n",
    "    \n",
    ")\n",
    "trainer.fit(learn, trainloader, val_dataloaders = testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T09:20:53.913565Z",
     "start_time": "2021-05-30T09:20:46.290Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "results = trainer.test(learn, testloader)\n",
    "base_path = \"results/{}\".format(\"person_lcde\")\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "with open(\"{}/pt_ode_lstm_{}.csv\".format(base_path, 128), \"a\") as f:\n",
    "    f.write(\"{:06f}\\n\".format(results[0][\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T09:23:28.947473Z",
     "start_time": "2021-05-30T09:23:28.926412Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_path = \"./logs/models/demons/cde/epoch=5-step=269.ckpt\"\n",
    "checkpoint = torch.load(best_path)\n",
    "states = {}\n",
    "for k_new, k_old in zip(cde.state_dict().keys(), checkpoint['state_dict'].keys()):\n",
    "    states[k_new] = checkpoint['state_dict'].get(k_old)\n",
    "cde.load_state_dict(state_dict = states)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T09:24:38.381951Z",
     "start_time": "2021-05-30T09:23:31.716756Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 12/12 [01:06<00:00,  5.55s/it]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'val_acc': 0.8007605075836182,\n",
      " 'val_f1': 0.7121887803077698,\n",
      " 'val_loss': 1.0005437135696411}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "learn = IrregularSequenceLearner(cde, lr=0.01, timestamps=False,  class_weights = 1/class_balance)\n",
    "\n",
    "results = trainer.test(learn, testloader)\n",
    "base_path = \"results/{}\".format(\"person\")\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "with open(\"{}/pt_ode_lstm_{}.csv\".format(base_path, 128), \"a\") as f:\n",
    "    f.write(\"{:06f}\\n\".format(results[0][\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ODELSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T10:24:03.905372Z",
     "start_time": "2021-05-30T10:24:03.900613Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_f1',\n",
    "    mode = 'max',\n",
    "    dirpath='logs/models/demons/odelstm/',\n",
    "    save_top_k = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T10:24:06.319351Z",
     "start_time": "2021-05-30T10:24:06.303473Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'P300Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0ef42b5e9134>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m trainloader, testloader, in_features, num_classes, return_sequences, class_balance = load_dataset(\n\u001b[0;32m----> 2\u001b[0;31m     'p300', timestamps=True, coeffs=False, batch_size=1024,  data_dir = '../data/demons/nery_demons_dataset')\n\u001b[0m",
      "\u001b[0;32m~/GitHub/MasterThesis/mt_code/datasets/utils.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(ds, timestamps, coeffs, batch_size, data_dir)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtest_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'p300'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mP300Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data_for_experiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mtrain_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'P300Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "trainloader, testloader, in_features, num_classes, return_sequences, class_balance = load_dataset(\n",
    "    'p300', timestamps=True, coeffs=False, batch_size=1024,  data_dir = '../data/demons/nery_demons_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T09:31:03.440505Z",
     "start_time": "2021-05-30T09:31:03.433893Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alina/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "accuracy =  torchmetrics.Accuracy()\n",
    "f1 =  torchmetrics.F1(num_classes, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T09:31:03.453757Z",
     "start_time": "2021-05-30T09:31:03.444406Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "olstm = OdeLstm(\n",
    "    8,#original num of features\n",
    "    8,\n",
    "    num_classes,\n",
    "\n",
    "    return_sequences=False,\n",
    "    #memory = True,\n",
    "    #gated=True\n",
    "    #solver_type='fixed_rk4',\n",
    ")\n",
    "learn = IrregularSequenceLearner(olstm, lr=0.05, timestamps=True, class_weights = 1/class_balance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T09:31:04.073355Z",
     "start_time": "2021-05-30T09:31:03.455258Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | OdeLstm | 738   \n",
      "----------------------------------\n",
      "738       Trainable params\n",
      "0         Non-trainable params\n",
      "738       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "t must be strictly increasing or decreasing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-4ea1bd0dd63c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;31m# dispath `start_training` or `start_testing` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_or_test_or_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;31m# set stage for logging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m    862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_sanity_val_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_sanity_check_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, max_batches, on_epoch)\u001b[0m\n\u001b[1;32m    724\u001b[0m                 \u001b[0;31m# lightning module methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"evaluation_step_and_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mevaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# capture any logged information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-7f3cefee368b>\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/MasterThesis/mt_code/models/ode_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, timespans, mask)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimespans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mcurrent_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GitHub/MasterThesis/mt_code/models/ode_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx, ts)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0ms_sort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_sort\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;31m# HACK: Make sure no two points are equal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mtrajectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_sort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mnew_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/torchdyn/models/neuralde.py\u001b[0m in \u001b[0;36mtrajectory\u001b[0;34m(self, x, s_span)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prep_odeint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         sol = torchdiffeq.odeint(self.defunc, x, s_span,\n\u001b[0;32m---> 95\u001b[0;31m                                  rtol=self.rtol, atol=self.atol, method=self.solver)\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/torchdiffeq/_impl/odeint.py\u001b[0m in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mshapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_is_reversed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSOLVERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSOLVERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/torchdiffeq/_impl/misc.py\u001b[0m in \u001b[0;36m_check_inputs\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn, SOLVERS)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;31m# Normalise time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0m_check_timelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0mt_is_reversed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/torchdiffeq/_impl/misc.py\u001b[0m in \u001b[0;36m_check_timelike\u001b[0;34m(name, timelike, can_grad)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtimelike\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"{} cannot require gradient\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimelike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtimelike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'{} must be strictly increasing or decreasing'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: t must be strictly increasing or decreasing"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    gradient_clip_val=1,\n",
    "    callbacks=[checkpoint_callback]\n",
    "    \n",
    ")\n",
    "trainer.fit(learn, trainloader, val_dataloaders = testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T09:25:07.404935Z",
     "start_time": "2021-05-30T09:24:51.306Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "results = trainer.test(learn, testloader)\n",
    "base_path = \"results/{}\".format(\"person_lcde\")\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "with open(\"{}/pt_ode_lstm_{}.csv\".format(base_path, 128), \"a\") as f:\n",
    "    f.write(\"{:06f}\\n\".format(results[0][\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### LMULSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T10:27:10.769160Z",
     "start_time": "2021-05-30T10:27:10.765929Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alina/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: Checkpoint directory logs/models/demons/lmulstm/ exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_f1',\n",
    "    mode = 'max',\n",
    "    dirpath='logs/models/demons/lmulstm/',\n",
    "    save_top_k = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T10:27:29.271781Z",
     "start_time": "2021-05-30T10:27:10.990715Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape:  torch.Size([45232, 35, 8])\n",
      "train_y.shape:  torch.Size([45232])\n",
      "Total number of train sequences: 45232\n",
      "Total number of test  sequences: 11308\n",
      "torch.Size([45232, 35, 1]) torch.Size([45232, 35, 8])\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader, in_features, num_classes, return_sequences, class_balance = load_dataset(\n",
    "    'p300', timestamps=False, coeffs=False, batch_size=1024,  data_dir = '../data/demons/nery_demons_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T10:27:29.280170Z",
     "start_time": "2021-05-30T10:27:29.273663Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alina/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "lmu = LmuLstm(\n",
    "    8,#original num of features\n",
    "    8,\n",
    "    8,\n",
    "    num_classes,\n",
    "    theta = 5,\n",
    "    return_sequences=False,\n",
    "    #memory = True,\n",
    "    #gated=True\n",
    "    #solver_type='fixed_rk4',\n",
    ")\n",
    "learn = IrregularSequenceLearner(lmu, lr=0.05, timestamps=False, class_weights = 1/class_balance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T10:27:51.576882Z",
     "start_time": "2021-05-30T10:27:29.281876Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name     | Type     | Params\n",
      "--------------------------------------\n",
      "0 | model    | LmuLstm  | 450   \n",
      "1 | accuracy | Accuracy | 0     \n",
      "2 | f1       | F1       | 0     \n",
      "--------------------------------------\n",
      "450       Trainable params\n",
      "0         Non-trainable params\n",
      "450       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/57 [00:00<?, ?it/s]                       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../mt_code/models/lmu_torch.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return (AT.to(dtype=torch.float32), torch.tensor(B, dtype=torch.float32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  79%|███████▉  | 45/57 [00:01<00:00, 26.75it/s, loss=0.502, v_num=60, val_loss=1.200, val_f1=0.711, val_acc=0.792, train_acc=0.806, train_f1=0.719, train_loss=0.495]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  82%|████████▏ | 47/57 [00:01<00:00, 25.81it/s, loss=0.502, v_num=60, val_loss=1.200, val_f1=0.711, val_acc=0.792, train_acc=0.806, train_f1=0.719, train_loss=0.495]\n",
      "Epoch 0: 100%|██████████| 57/57 [00:02<00:00, 28.17it/s, loss=0.502, v_num=60, val_loss=0.866, val_f1=0.712, val_acc=0.801, train_acc=0.744, train_f1=0.635, train_loss=0.578]\n",
      "Epoch 1:  79%|███████▉  | 45/57 [00:01<00:00, 26.92it/s, loss=0.507, v_num=60, val_loss=0.866, val_f1=0.712, val_acc=0.801, train_acc=0.796, train_f1=0.705, train_loss=0.511]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 48/57 [00:01<00:00, 26.41it/s, loss=0.507, v_num=60, val_loss=0.866, val_f1=0.712, val_acc=0.801, train_acc=0.796, train_f1=0.705, train_loss=0.511]\n",
      "Epoch 1: 100%|██████████| 57/57 [00:02<00:00, 28.27it/s, loss=0.507, v_num=60, val_loss=0.920, val_f1=0.712, val_acc=0.801, train_acc=0.767, train_f1=0.666, train_loss=0.552]\n",
      "Epoch 2:  79%|███████▉  | 45/57 [00:01<00:00, 25.62it/s, loss=0.501, v_num=60, val_loss=0.920, val_f1=0.712, val_acc=0.801, train_acc=0.824, train_f1=0.745, train_loss=0.466]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 48/57 [00:01<00:00, 25.06it/s, loss=0.501, v_num=60, val_loss=0.920, val_f1=0.712, val_acc=0.801, train_acc=0.824, train_f1=0.745, train_loss=0.466]\n",
      "Epoch 2:  95%|█████████▍| 54/57 [00:02<00:00, 26.60it/s, loss=0.501, v_num=60, val_loss=0.920, val_f1=0.712, val_acc=0.801, train_acc=0.824, train_f1=0.745, train_loss=0.466]\n",
      "Epoch 2: 100%|██████████| 57/57 [00:02<00:00, 27.00it/s, loss=0.501, v_num=60, val_loss=0.957, val_f1=0.712, val_acc=0.801, train_acc=0.784, train_f1=0.689, train_loss=0.525]\n",
      "Epoch 3:  79%|███████▉  | 45/57 [00:01<00:00, 26.69it/s, loss=0.497, v_num=60, val_loss=0.957, val_f1=0.712, val_acc=0.801, train_acc=0.806, train_f1=0.719, train_loss=0.503]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 48/57 [00:01<00:00, 25.99it/s, loss=0.497, v_num=60, val_loss=0.957, val_f1=0.712, val_acc=0.801, train_acc=0.806, train_f1=0.719, train_loss=0.503]\n",
      "Epoch 3:  95%|█████████▍| 54/57 [00:01<00:00, 27.39it/s, loss=0.497, v_num=60, val_loss=0.957, val_f1=0.712, val_acc=0.801, train_acc=0.806, train_f1=0.719, train_loss=0.503]\n",
      "Epoch 3: 100%|██████████| 57/57 [00:02<00:00, 27.82it/s, loss=0.497, v_num=60, val_loss=0.956, val_f1=0.712, val_acc=0.801, train_acc=0.790, train_f1=0.697, train_loss=0.515]\n",
      "Epoch 4:  79%|███████▉  | 45/57 [00:01<00:00, 27.04it/s, loss=0.51, v_num=60, val_loss=0.956, val_f1=0.712, val_acc=0.801, train_acc=0.799, train_f1=0.709, train_loss=0.507] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 48/57 [00:01<00:00, 26.55it/s, loss=0.51, v_num=60, val_loss=0.956, val_f1=0.712, val_acc=0.801, train_acc=0.799, train_f1=0.709, train_loss=0.507]\n",
      "Epoch 4:  95%|█████████▍| 54/57 [00:01<00:00, 27.77it/s, loss=0.51, v_num=60, val_loss=0.956, val_f1=0.712, val_acc=0.801, train_acc=0.799, train_f1=0.709, train_loss=0.507]\n",
      "Epoch 4: 100%|██████████| 57/57 [00:02<00:00, 27.84it/s, loss=0.51, v_num=60, val_loss=0.897, val_f1=0.712, val_acc=0.801, train_acc=0.716, train_f1=0.597, train_loss=0.617]\n",
      "Epoch 5:  79%|███████▉  | 45/57 [00:01<00:00, 26.49it/s, loss=0.502, v_num=60, val_loss=0.897, val_f1=0.712, val_acc=0.801, train_acc=0.831, train_f1=0.754, train_loss=0.452]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 48/57 [00:01<00:00, 25.86it/s, loss=0.502, v_num=60, val_loss=0.897, val_f1=0.712, val_acc=0.801, train_acc=0.831, train_f1=0.754, train_loss=0.452]\n",
      "Epoch 5:  95%|█████████▍| 54/57 [00:01<00:00, 27.40it/s, loss=0.502, v_num=60, val_loss=0.897, val_f1=0.712, val_acc=0.801, train_acc=0.831, train_f1=0.754, train_loss=0.452]\n",
      "Epoch 5: 100%|██████████| 57/57 [00:02<00:00, 27.77it/s, loss=0.502, v_num=60, val_loss=0.982, val_f1=0.712, val_acc=0.801, train_acc=0.790, train_f1=0.697, train_loss=0.523]\n",
      "Epoch 6:  79%|███████▉  | 45/57 [00:01<00:00, 26.41it/s, loss=0.502, v_num=60, val_loss=0.982, val_f1=0.712, val_acc=0.801, train_acc=0.791, train_f1=0.699, train_loss=0.515]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 48/57 [00:01<00:00, 25.79it/s, loss=0.502, v_num=60, val_loss=0.982, val_f1=0.712, val_acc=0.801, train_acc=0.791, train_f1=0.699, train_loss=0.515]\n",
      "Epoch 6:  95%|█████████▍| 54/57 [00:01<00:00, 27.16it/s, loss=0.502, v_num=60, val_loss=0.982, val_f1=0.712, val_acc=0.801, train_acc=0.791, train_f1=0.699, train_loss=0.515]\n",
      "Epoch 6: 100%|██████████| 57/57 [00:02<00:00, 27.45it/s, loss=0.502, v_num=60, val_loss=0.918, val_f1=0.712, val_acc=0.801, train_acc=0.801, train_f1=0.713, train_loss=0.499]\n",
      "Epoch 7:  79%|███████▉  | 45/57 [00:01<00:00, 23.51it/s, loss=0.504, v_num=60, val_loss=0.918, val_f1=0.712, val_acc=0.801, train_acc=0.808, train_f1=0.722, train_loss=0.492]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 48/57 [00:02<00:00, 23.19it/s, loss=0.504, v_num=60, val_loss=0.918, val_f1=0.712, val_acc=0.801, train_acc=0.808, train_f1=0.722, train_loss=0.492]\n",
      "Epoch 7:  95%|█████████▍| 54/57 [00:02<00:00, 24.72it/s, loss=0.504, v_num=60, val_loss=0.918, val_f1=0.712, val_acc=0.801, train_acc=0.808, train_f1=0.722, train_loss=0.492]\n",
      "Epoch 7: 100%|██████████| 57/57 [00:02<00:00, 25.09it/s, loss=0.504, v_num=60, val_loss=0.889, val_f1=0.712, val_acc=0.801, train_acc=0.784, train_f1=0.689, train_loss=0.517]\n",
      "Epoch 8:  79%|███████▉  | 45/57 [00:01<00:00, 26.67it/s, loss=0.504, v_num=60, val_loss=0.889, val_f1=0.712, val_acc=0.801, train_acc=0.794, train_f1=0.703, train_loss=0.513]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 48/57 [00:01<00:00, 26.13it/s, loss=0.504, v_num=60, val_loss=0.889, val_f1=0.712, val_acc=0.801, train_acc=0.794, train_f1=0.703, train_loss=0.513]\n",
      "Epoch 8:  95%|█████████▍| 54/57 [00:01<00:00, 27.72it/s, loss=0.504, v_num=60, val_loss=0.889, val_f1=0.712, val_acc=0.801, train_acc=0.794, train_f1=0.703, train_loss=0.513]\n",
      "Epoch 8: 100%|██████████| 57/57 [00:02<00:00, 27.99it/s, loss=0.504, v_num=60, val_loss=0.927, val_f1=0.712, val_acc=0.801, train_acc=0.818, train_f1=0.736, train_loss=0.479]\n",
      "Epoch 9:  79%|███████▉  | 45/57 [00:01<00:00, 25.58it/s, loss=0.496, v_num=60, val_loss=0.927, val_f1=0.712, val_acc=0.801, train_acc=0.801, train_f1=0.712, train_loss=0.502]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 48/57 [00:01<00:00, 24.82it/s, loss=0.496, v_num=60, val_loss=0.927, val_f1=0.712, val_acc=0.801, train_acc=0.801, train_f1=0.712, train_loss=0.502]\n",
      "Epoch 9:  95%|█████████▍| 54/57 [00:02<00:00, 26.31it/s, loss=0.496, v_num=60, val_loss=0.927, val_f1=0.712, val_acc=0.801, train_acc=0.801, train_f1=0.712, train_loss=0.502]\n",
      "Epoch 9: 100%|██████████| 57/57 [00:02<00:00, 26.66it/s, loss=0.496, v_num=60, val_loss=0.943, val_f1=0.712, val_acc=0.801, train_acc=0.767, train_f1=0.666, train_loss=0.552]\n",
      "Epoch 9: 100%|██████████| 57/57 [00:02<00:00, 26.60it/s, loss=0.496, v_num=60, val_loss=0.943, val_f1=0.712, val_acc=0.801, train_acc=0.767, train_f1=0.666, train_loss=0.552]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    gradient_clip_val=1,\n",
    "    callbacks=[checkpoint_callback]\n",
    "    \n",
    ")\n",
    "trainer.fit(learn, trainloader, val_dataloaders = testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T10:27:52.023749Z",
     "start_time": "2021-05-30T10:27:51.580039Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 12/12 [00:00<00:00, 27.94it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'val_acc': 0.8007605075836182,\n",
      " 'val_f1': 0.7121887803077698,\n",
      " 'val_loss': 0.943478524684906}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "results = trainer.test(learn, testloader)\n",
    "base_path = \"results/{}\".format(\"person_lcde\")\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "with open(\"{}/pt_ode_lstm_{}.csv\".format(base_path, 128), \"a\") as f:\n",
    "    f.write(\"{:06f}\\n\".format(results[0][\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T10:39:45.212127Z",
     "start_time": "2021-05-30T10:39:45.208237Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = (2\n",
    "    +3\n",
    "    +4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T10:39:46.866296Z",
     "start_time": "2021-05-30T10:39:46.857928Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### CDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.604545Z",
     "start_time": "2021-05-30T03:19:52.348Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_f1',\n",
    "    mode = 'max',\n",
    "    dirpath='logs/models/activity/cde/',\n",
    "    save_top_k = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.605151Z",
     "start_time": "2021-05-30T03:19:52.354Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trainloader, testloader, in_features, num_classes, return_sequences, class_balance = load_dataset(\n",
    "    timestamps=False, coeffs=True, batch_size=512, data_dir='../data/person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.605844Z",
     "start_time": "2021-05-30T03:19:52.359Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cde = NeuralCde(\n",
    "    7,#original num of features\n",
    "    8,\n",
    "    num_classes,\n",
    "\n",
    "    return_sequences=True,\n",
    "    #memory = True,\n",
    "    #gated=True\n",
    "    #solver_type='fixed_rk4',\n",
    ")\n",
    "learn = IrregularSequenceLearner(cde, lr=0.05, timestamps=False, class_weights = 1/class_balance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.606740Z",
     "start_time": "2021-05-30T03:19:52.363Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    gradient_clip_val=1,\n",
    "    callbacks=[checkpoint_callback]\n",
    "    \n",
    ")\n",
    "trainer.fit(learn, trainloader, val_dataloaders = testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.607492Z",
     "start_time": "2021-05-30T03:19:52.370Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "results = trainer.test(learn, testloader)\n",
    "base_path = \"results/{}\".format(\"person_lcde\")\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "with open(\"{}/pt_ode_lstm_{}.csv\".format(base_path, 128), \"a\") as f:\n",
    "    f.write(\"{:06f}\\n\".format(results[0][\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.608255Z",
     "start_time": "2021-05-30T03:19:52.377Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_path = checkpoint_callback.best_model_path\n",
    "checkpoint = torch.load(best_path)\n",
    "states = {}\n",
    "for k_new, k_old in zip(cde.state_dict().keys(), checkpoint['state_dict'].keys()):\n",
    "    states[k_new] = checkpoint['state_dict'].get(k_old)\n",
    "cde.load_state_dict(state_dict = states)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.609190Z",
     "start_time": "2021-05-30T03:19:52.381Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = IrregularSequenceLearner(cde, lr=0.01, timestamps=False,  class_weights = 1/class_balance)\n",
    "\n",
    "results = trainer.test(learn, testloader)\n",
    "base_path = \"results/{}\".format(\"person\")\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "with open(\"{}/pt_ode_lstm_{}.csv\".format(base_path, 128), \"a\") as f:\n",
    "    f.write(\"{:06f}\\n\".format(results[0][\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### ODELSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.610231Z",
     "start_time": "2021-05-30T03:19:52.387Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_exp(model_cls, logpath = 'logs/tmp'):\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        monitor='val_f1',\n",
    "        mode = 'max',\n",
    "        dirpath=logpath,\n",
    "        save_top_k = 3,\n",
    "    )\n",
    "    \n",
    "    trainloader, testloader, in_features, num_classes, return_sequences, class_balance = load_dataset()\n",
    "    \n",
    "    model = model_cls(\n",
    "        in_features,\n",
    "        128,\n",
    "        num_classes,\n",
    "        return_sequences=return_sequences,\n",
    "        solver_type='fixed_rk4',\n",
    "    )\n",
    "    learn = IrregularSequenceLearner(model, lr=0.01, class_weights = 1/class_balance)\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=10,\n",
    "        progress_bar_refresh_rate=1,\n",
    "        gradient_clip_val=1,\n",
    "        callbacks=[checkpoint_callback]\n",
    "\n",
    "    )\n",
    "    trainer.fit(learn, trainloader, val_dataloaders = testloader)\n",
    "\n",
    "    \n",
    "    best_path = checkpoint_callback.best_model_path\n",
    "    checkpoint = torch.load(best_path)\n",
    "    states = {}\n",
    "    for k_new, k_old in zip(ode_lstm.state_dict().keys(), checkpoint['state_dict'].keys()):\n",
    "        states[k_new] = checkpoint['state_dict'].get(k_old)\n",
    "    ode_lstm.load_state_dict(state_dict = states)\n",
    "\n",
    "\n",
    "    learn = IrregularSequenceLearner(ode_lstm, lr=0.01, class_weights = 1/class_balance)\n",
    "\n",
    "    results = trainer.test(learn, testloader)\n",
    "    base_path = \"results/{}\".format(\"person\")\n",
    "    os.makedirs(base_path, exist_ok=True)\n",
    "    with open(\"{}/pt_ode_lstm_{}.csv\".format(base_path, 128), \"a\") as f:\n",
    "        f.write(\"{:06f}\\n\".format(results[0][\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.610947Z",
     "start_time": "2021-05-30T03:19:52.393Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_f1',\n",
    "    mode = 'max',\n",
    "    dirpath='logs/models/activity/odelstm/',\n",
    "    save_top_k = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.611789Z",
     "start_time": "2021-05-30T03:19:52.397Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "trainloader, testloader, in_features, num_classes, return_sequences, class_balance = load_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.612476Z",
     "start_time": "2021-05-30T03:19:52.402Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ode_lstm = OdeLstm(\n",
    "    in_features,\n",
    "    128,\n",
    "    num_classes,\n",
    "    return_sequences=return_sequences,\n",
    "    solver_type='fixed_rk4',\n",
    ")\n",
    "learn = IrregularSequenceLearner(ode_lstm, lr=0.01, class_weights = 1/class_balance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.613213Z",
     "start_time": "2021-05-30T03:19:52.407Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    gradient_clip_val=1,\n",
    "    callbacks=[checkpoint_callback]\n",
    "    \n",
    ")\n",
    "trainer.fit(learn, trainloader, val_dataloaders = testloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.613953Z",
     "start_time": "2021-05-30T03:19:52.412Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "results = trainer.test(learn, testloader)\n",
    "base_path = \"results/{}\".format(\"person\")\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "with open(\"{}/pt_ode_lstm_{}.csv\".format(base_path, 128), \"a\") as f:\n",
    "    f.write(\"{:06f}\\n\".format(results[0][\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.614896Z",
     "start_time": "2021-05-30T03:19:52.417Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_path = checkpoint_callback.best_model_path\n",
    "checkpoint = torch.load(best_path)\n",
    "states = {}\n",
    "for k_new, k_old in zip(ode_lstm.state_dict().keys(), checkpoint['state_dict'].keys()):\n",
    "    states[k_new] = checkpoint['state_dict'].get(k_old)\n",
    "ode_lstm.load_state_dict(state_dict = states)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.615469Z",
     "start_time": "2021-05-30T03:19:52.421Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = IrregularSequenceLearner(ode_lstm, lr=0.01, class_weights = 1/class_balance)\n",
    "\n",
    "results = trainer.test(learn, testloader)\n",
    "base_path = \"results/{}\".format(\"person\")\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "with open(\"{}/pt_ode_lstm_{}.csv\".format(base_path, 128), \"a\") as f:\n",
    "    f.write(\"{:06f}\\n\".format(results[0][\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMULSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T16:28:26.107087Z",
     "start_time": "2021-05-30T16:28:26.097012Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alina/conda/anaconda3/envs/neiry/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: Checkpoint directory logs/models/activity/lmulstm/ exists and is not empty.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_f1',\n",
    "    mode = 'max',\n",
    "    dirpath='logs/models/activity/lmulstm/',\n",
    "    save_top_k = 3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T16:28:28.311581Z",
     "start_time": "2021-05-30T16:28:26.247803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7769, 32, 1]) torch.Size([7769, 32, 7])\n"
     ]
    }
   ],
   "source": [
    "trainloader, testloader, in_features, num_classes, return_sequences, class_balance = load_dataset(\n",
    "    timestamps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T16:31:05.193946Z",
     "start_time": "2021-05-30T16:31:05.172442Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "lmu_lstm = LmuLstm(\n",
    "    in_features,\n",
    "    128,\n",
    "    128,\n",
    "    num_classes,\n",
    "    5,\n",
    "    return_sequences=return_sequences,\n",
    "    memory = True,\n",
    "    #gated=True\n",
    "    #solver_type='fixed_rk4',\n",
    ")\n",
    "learn = IrregularSequenceLearner(lmu_lstm, lr=0.01, timestamps=False, class_weights = 1/class_balance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T16:31:05.360007Z",
     "start_time": "2021-05-30T16:31:05.356154Z"
    }
   },
   "outputs": [],
   "source": [
    "def printgradnorm(self, grad_input, grad_output):\n",
    "\n",
    "    print('grad_input size:', grad_input[0].size())\n",
    "    print('grad_output size:', grad_output[0].size())\n",
    "    print('grad_input norm:', grad_input[0].norm())\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T16:31:05.580627Z",
     "start_time": "2021-05-30T16:31:05.574001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f588c430bd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmu_lstm.rnn_cell.memory_encoder.register_backward_hook(printgradnorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T16:31:08.880310Z",
     "start_time": "2021-05-30T16:31:06.157738Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name     | Type     | Params\n",
      "--------------------------------------\n",
      "0 | model    | LmuLstm  | 69.0 K\n",
      "1 | accuracy | Accuracy | 0     \n",
      "2 | f1       | F1       | 0     \n",
      "--------------------------------------\n",
      "69.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "69.0 K    Total params\n",
      "0.276     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/77 [00:00<?, ?it/s]                       grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:   1%|▏         | 1/77 [00:00<00:13,  5.57it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:   3%|▎         | 2/77 [00:00<00:10,  7.34it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.271, train_f1=0.194, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:   4%|▍         | 3/77 [00:00<00:09,  7.95it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.413, train_f1=0.242, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:   5%|▌         | 4/77 [00:00<00:08,  8.29it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.384, train_f1=0.213, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:   6%|▋         | 5/77 [00:00<00:08,  8.53it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.297, train_f1=0.136, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   8%|▊         | 6/77 [00:00<00:08,  8.74it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.411, train_f1=0.239, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:   9%|▉         | 7/77 [00:00<00:08,  8.64it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.361, train_f1=0.191, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:  10%|█         | 8/77 [00:00<00:07,  8.81it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.323, train_f1=0.158, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:  12%|█▏        | 9/77 [00:01<00:07,  8.87it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.369, train_f1=0.199, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:  13%|█▎        | 10/77 [00:01<00:07,  8.86it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.372, train_f1=0.201, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  14%|█▍        | 11/77 [00:01<00:07,  8.86it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.351, train_f1=0.182, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:  16%|█▌        | 12/77 [00:01<00:07,  8.95it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.350, train_f1=0.182, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:  17%|█▋        | 13/77 [00:01<00:07,  8.97it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.448, train_f1=0.277, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  18%|█▊        | 14/77 [00:01<00:06,  9.01it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.459, train_f1=0.289, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:  19%|█▉        | 15/77 [00:01<00:06,  9.04it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.339, train_f1=0.171, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:  21%|██        | 16/77 [00:01<00:06,  9.05it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.361, train_f1=0.191, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:  22%|██▏       | 17/77 [00:01<00:06,  8.98it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.413, train_f1=0.241, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:  23%|██▎       | 18/77 [00:02<00:06,  8.98it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.366, train_f1=0.197, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  25%|██▍       | 19/77 [00:02<00:06,  8.97it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.408, train_f1=0.237, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:  26%|██▌       | 20/77 [00:02<00:06,  9.03it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.360, train_f1=0.190, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:  27%|██▋       | 21/77 [00:02<00:06,  9.01it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.428, train_f1=0.257, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  29%|██▊       | 22/77 [00:02<00:06,  9.04it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.398, train_f1=0.227, train_loss=nan.0]grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "grad_input size: torch.Size([128])\n",
      "grad_output size: torch.Size([128, 128])\n",
      "grad_input norm: tensor(nan)\n",
      "Epoch 0:  29%|██▊       | 22/77 [00:02<00:06,  8.70it/s, loss=nan, v_num=74, val_loss=nan.0, val_f1=0.269, val_acc=0.337, train_acc=0.398, train_f1=0.227, train_loss=nan.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    progress_bar_refresh_rate=1,\n",
    "    gradient_clip_val=0.01,\n",
    "    callbacks=[checkpoint_callback]\n",
    "    \n",
    ")\n",
    "trainer.fit(learn, trainloader, val_dataloaders = testloader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.618375Z",
     "start_time": "2021-05-30T03:19:52.446Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "results = trainer.test(learn, testloader)\n",
    "base_path = \"results/{}\".format(\"person_lmu\")\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "with open(\"{}/pt_ode_lstm_{}.csv\".format(base_path, 128), \"a\") as f:\n",
    "    f.write(\"{:06f}\\n\".format(results[0][\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.619022Z",
     "start_time": "2021-05-30T03:19:52.451Z"
    }
   },
   "outputs": [],
   "source": [
    "best_path = checkpoint_callback.best_model_path\n",
    "checkpoint = torch.load(best_path)\n",
    "states = {}\n",
    "for k_new, k_old in zip(lmu_lstm.state_dict().keys(), checkpoint['state_dict'].keys()):\n",
    "    states[k_new] = checkpoint['state_dict'].get(k_old)\n",
    "lmu_lstm.load_state_dict(state_dict = states)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.619650Z",
     "start_time": "2021-05-30T03:19:52.454Z"
    }
   },
   "outputs": [],
   "source": [
    "learn = IrregularSequenceLearner(lmu_lstm, lr=0.01, timestamps=False, class_weights = 1/class_balance)\n",
    "\n",
    "results = trainer.test(learn, testloader)\n",
    "base_path = \"results/{}\".format(\"person\")\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "with open(\"{}/pt_ode_lstm_{}.csv\".format(base_path, 128), \"a\") as f:\n",
    "    f.write(\"{:06f}\\n\".format(results[0][\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.620340Z",
     "start_time": "2021-05-30T03:19:52.462Z"
    }
   },
   "outputs": [],
   "source": [
    "train_X, train_y = get_data()\n",
    "######################\n",
    "# input_channels=3 because we have both the horizontal and vertical position of a point in the spiral, \n",
    "# and time.\n",
    "# hidden_channels=8 is the number of hidden channels for the evolving z_t, which we get to choose.\n",
    "# output_channels=1 because we're doing binary classification.\n",
    "######################\n",
    "model =  LmuLstm(\n",
    "    in_features = 2, hidden_size = 8, order = 8, \n",
    "    out_feature = 1, theta = 0.005, memory = False\n",
    ")#ODELSTM(in_features=2, hidden_size=8, out_feature=1, return_sequences=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "######################\n",
    "# Now we turn our dataset into a continuous path. We do this here via natural cubic spline interpolation.\n",
    "# The resulting `train_coeffs` are some tensors describing the path.\n",
    "# For most problems, it's advisable to save these coeffs and treat them as the dataset, \n",
    "# as this interpolation can take a long time.\n",
    "######################\n",
    "#train_coeffs = controldiffeq.natural_cubic_spline_coeffs(train_t, train_X)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma=0.75)\n",
    "train_dataset = torch.utils.data.TensorDataset(train_X, train_y)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=32)\n",
    "for epoch in range(30):\n",
    "    for batch in train_dataloader:\n",
    "        batch_x, batch_y = batch\n",
    "        pred_y = model(batch_x[:, :, 1:])#, batch_x[:, :, 0]).squeeze(-1)\n",
    "        loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "            pred_y, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('Epoch: {}   Training loss: {}    lr: {}'.format(epoch, loss.item(), optimizer.param_groups[0]['lr']))\n",
    "\n",
    "\n",
    "test_X, test_y = get_data()\n",
    "pred_y = model(test_X[:, :, 1:]).squeeze(-1)\n",
    "binary_prediction = (torch.sigmoid(pred_y) > 0.5).to(test_y.dtype)\n",
    "prediction_matches = (binary_prediction == test_y).to(test_y.dtype)\n",
    "proportion_correct = prediction_matches.sum() / test_y.size(0)\n",
    "print('Test Accuracy: {}'.format(proportion_correct))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.620902Z",
     "start_time": "2021-05-30T03:19:52.465Z"
    }
   },
   "outputs": [],
   "source": [
    "train_X, train_y = get_data()\n",
    "######################\n",
    "# input_channels=3 because we have both the horizontal and vertical position of a point in the spiral, \n",
    "# and time.\n",
    "# hidden_channels=8 is the number of hidden channels for the evolving z_t, which we get to choose.\n",
    "# output_channels=1 because we're doing binary classification.\n",
    "######################\n",
    "model = OdeLstm(in_features=2, hidden_size=8, out_feature=1, return_sequences=False)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "######################\n",
    "# Now we turn our dataset into a continuous path. We do this here via natural cubic spline interpolation.\n",
    "# The resulting `train_coeffs` are some tensors describing the path.\n",
    "# For most problems, it's advisable to save these coeffs and treat them as the dataset, \n",
    "# as this interpolation can take a long time.\n",
    "######################\n",
    "#train_coeffs = controldiffeq.natural_cubic_spline_coeffs(train_t, train_X)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma=0.75)\n",
    "train_dataset = torch.utils.data.TensorDataset(train_X, train_y)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=32)\n",
    "for epoch in range(30):\n",
    "    for batch in train_dataloader:\n",
    "        batch_x, batch_y = batch\n",
    "        pred_y = model(batch_x[:, :, 1:], batch_x[:, :, 0]).squeeze(-1)\n",
    "        loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "            pred_y, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('Epoch: {}   Training loss: {}    lr: {}'.format(epoch, loss.item(), optimizer.param_groups[0]['lr']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.621459Z",
     "start_time": "2021-05-30T03:19:52.471Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "test_X, test_y = get_data()\n",
    "pred_y = model(test_X[:, :, 1:], test_X[:, :, 0]).squeeze(-1)\n",
    "binary_prediction = (torch.sigmoid(pred_y) > 0.5).to(test_y.dtype)\n",
    "prediction_matches = (binary_prediction == test_y).to(test_y.dtype)\n",
    "proportion_correct = prediction_matches.sum() / test_y.size(0)\n",
    "print('Test Accuracy: {}'.format(proportion_correct))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-30T03:20:32.622109Z",
     "start_time": "2021-05-30T03:19:52.477Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs=30\n",
    "train_X, train_y = get_data()\n",
    "\n",
    "######################\n",
    "# input_channels=3 because we have both the horizontal and vertical position of a point in the spiral, and time.\n",
    "# hidden_channels=8 is the number of hidden channels for the evolving z_t, which we get to choose.\n",
    "# output_channels=1 because we're doing binary classification.\n",
    "######################\n",
    "model =NeuralCde(input_channels=3, hidden_channels=8, output_channels=1)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "######################\n",
    "# Now we turn our dataset into a continuous path. We do this here via natural cubic spline interpolation.\n",
    "# The resulting `train_coeffs` is a tensor describing the path.\n",
    "# For most problems, it's probably easiest to save this tensor and treat it as the dataset.\n",
    "######################\n",
    "train_coeffs = torchcde.natural_cubic_coeffs(train_X)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(train_coeffs, train_y)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32)\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch_coeffs, batch_y = batch\n",
    "        pred_y = model(batch_coeffs).squeeze(-1)\n",
    "        loss = torch.nn.functional.binary_cross_entropy_with_logits(pred_y, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    print('Epoch: {}   Training loss: {}'.format(epoch, loss.item()))\n",
    "\n",
    "test_X, test_y = get_data()\n",
    "test_coeffs = torchcde.natural_cubic_coeffs(test_X)\n",
    "pred_y = model(test_coeffs).squeeze(-1)\n",
    "binary_prediction = (torch.sigmoid(pred_y) > 0.5).to(test_y.dtype)\n",
    "prediction_matches = (binary_prediction == test_y).to(test_y.dtype)\n",
    "proportion_correct = prediction_matches.sum() / test_y.size(0)\n",
    "print('Test Accuracy: {}'.format(proportion_correct))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "neiry",
   "language": "python",
   "name": "neiry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
